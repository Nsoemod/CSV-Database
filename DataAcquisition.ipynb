{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import openreview\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pdfplumber\n",
    "from tqdm import tqdm"
   ],
   "id": "613dc8351fa20791"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_filename(name: str) -> str:\n",
    "    # remove special characters\n",
    "    name = re.sub(r'[<>:\"/\\\\|?*]', '', name)\n",
    "    name = re.sub(r'\\s+', '_', name).strip('_')\n",
    "    return name\n",
    "\n",
    "def download_neurips_articles():\n",
    "    try:\n",
    "        # initialize openreview client\n",
    "        client = openreview.api.OpenReviewClient(baseurl='https://api2.openreview.net')\n",
    "\n",
    "        # set up constants\n",
    "        ACCEPTED_VENUE_ID = 'NeurIPS.cc/2024/Datasets_and_Benchmarks_Track'\n",
    "        OUTPUT_DIR = 'NeurIPS2024_Datasets_and_Benchmarks'\n",
    "        METADATA_CSV_FILE = os.path.join(OUTPUT_DIR, 'metadata.csv')\n",
    "\n",
    "        # make output directory\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "        # get all accepted articles\n",
    "        print(f\"Querying openreview for venue ID: {ACCEPTED_VENUE_ID}\")\n",
    "        notes_iterator = openreview.tools.iterget_notes(client, content={'venueid': ACCEPTED_VENUE_ID})\n",
    "\n",
    "        #notes_iterator = openreview.tools.iterget_notes(client, content={'venueid': ACCEPTED_VENUE_ID})\n",
    "        all_notes = list(notes_iterator)\n",
    "        print(f\"Total notes retrieved: {len(all_notes)}\")\n",
    "\n",
    "        if not all_notes:\n",
    "            print(\"No accepted articles found\")\n",
    "            return\n",
    "\n",
    "        # downloading pdfs and metadata, extracting fulltext to .csv\n",
    "        all_metadata = []\n",
    "        print(f\"Downloading {len(all_notes)} articles to '{OUTPUT_DIR}'\")\n",
    "\n",
    "        for note in tqdm(all_notes):\n",
    "            try:\n",
    "                title = note.content['title']['value']\n",
    "                pdf_url_relative = note.content['pdf']['value']\n",
    "\n",
    "                pdf_url_full = f\"https://openreview.net{pdf_url_relative}\"\n",
    "                pdf_filename = f\"{clean_filename(title)}.pdf\"\n",
    "                pdf_path = os.path.join(OUTPUT_DIR, pdf_filename)\n",
    "\n",
    "                # download pdf\n",
    "                if not os.path.exists(pdf_path):\n",
    "                    response = requests.get(pdf_url_full, stream=True)\n",
    "                    response.raise_for_status()\n",
    "                    with open(pdf_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "\n",
    "                # extract fulltext\n",
    "                fulltext = \"\"\n",
    "                try:\n",
    "                    with pdfplumber.open(pdf_path) as pdf:\n",
    "                        fulltext = \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages)\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"Error extracting fulltext from {pdf_path}: {e}\")\n",
    "                    fulltext = \"Could not extract fulltext\"\n",
    "\n",
    "                # collect metadata\n",
    "                article_metadata = {\n",
    "                    'title': title,\n",
    "                    'keywords': note.content.get('keywords', {}).get('value', []),\n",
    "                    'openreview_url': f\"https://openreview.net/forum?id={note.id}\",\n",
    "                    'pdf_filename': pdf_filename,\n",
    "                    'fulltext': fulltext\n",
    "                }\n",
    "                all_metadata.append(article_metadata)\n",
    "\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error processing article '{note.content.get('title', {}).get('value', 'Unknown')}': {e}\")\n",
    "\n",
    "        if not all_metadata:\n",
    "            print(\"No metadata found\")\n",
    "            return\n",
    "\n",
    "        # save metadata to .csv\n",
    "        with open(METADATA_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=all_metadata[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_metadata)\n",
    "\n",
    "        print(f\"Metadata saved to '{METADATA_CSV_FILE}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing articles: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    download_neurips_articles()\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "12f76da31202c2c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('NeurIPS2024_Datasets_and_Benchmarks/metadata.csv')\n",
    "df.head()"
   ],
   "id": "623026b80a443c3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info()",
   "id": "ffb8713cccc048fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# checking for failed fulltext extractions\n",
    "empty_mask = df['fulltext'].fillna('').str.strip() == ''\n",
    "missing_fulltext = df.loc[empty_mask, ['title', 'pdf_filename']]\n",
    "\n",
    "if missing_fulltext.empty:\n",
    "    print(\"No failed fulltext extractions\")\n",
    "else:\n",
    "    print(\"Failed fulltext extractions:\")\n",
    "    print(missing_fulltext)"
   ],
   "id": "d8ac5e9fb976d8da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "# The failed fulltext extraction seems to be image-based. Will use tesseract to extract text instead.\n",
    "# I will manually input the fulltext into the .csv file, since it is only one article.\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def extract_text_from_image_pdf(pdf_path):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        full_text = \"\"\n",
    "        for i, image in enumerate(images):\n",
    "            print(f\"   - Reading page {i + 1}/{len(images)}\")\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            full_text += text + \"\\n\\n\" # Add page breaks\n",
    "\n",
    "        print(full_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during OCR processing: {e}\")\n",
    "        print(\"Please ensure Tesseract is installed and accessible in your system's PATH.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"LINGOLY_A_Benchmark_of_Olympiad-Level_Linguistic_Reasoning_Puzzles_in_Low_Resource_and_Extinct_Languages.pdf\"\n",
    "    folder = \"NeurIPS2024_Datasets_and_Benchmarks\"\n",
    "    file_to_process = os.path.join(folder, filename)\n",
    "\n",
    "    extract_text_from_image_pdf(file_to_process)\n",
    "\"\"\""
   ],
   "id": "b454ff68cef370df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#removing the row where the fulltext is empty\n",
    "df.to_csv('NeurIPS2024_Datasets_and_Benchmarks/backup_metadata.csv', index=False)"
   ],
   "id": "9411551a40fb8acf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "row = df.iloc[180]\n",
    "print(row['title'])\n",
    "df.info()"
   ],
   "id": "7007b2e759b88f04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# SIKRE AT DET ER DET RIGTIGE INDEx!!!!\n",
    "df = df.drop(df.index[180])"
   ],
   "id": "f260a566fe11e09c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "row = df.iloc[180]\n",
    "print(row['title'])\n",
    "df.info()"
   ],
   "id": "6beedcbbed6c6ada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_word_column():\n",
    "    file_path = os.path.join('NeurIPS2024_Datasets_and_Benchmarks', 'metadata.csv')\n",
    "\n",
    "    search_terms = {\n",
    "        'representation_mentioned': r'represent',\n",
    "        'diversity_mentioned': r'divers',\n",
    "        'similarity_mentioned': r'similar',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"Reading file: {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        for column_name, pattern in search_terms.items():\n",
    "            df[column_name] = df['fulltext'].str.contains(\n",
    "                pattern,\n",
    "                case=False,\n",
    "                regex=True\n",
    "            ).astype(int)\n",
    "\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        #checking the results\n",
    "        print(df[['title'] + list(search_terms.keys())].head())\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    add_word_column()"
   ],
   "id": "797579b254b7e1db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df2 = pd.read_csv('NeurIPS2024_Datasets_and_Benchmarks/metadata.csv')\n",
    "df2.info()"
   ],
   "id": "62fb9e25590d95bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#checking how many articles contain each of the three words and their frequency\n",
    "word_columns = ['representation_mentioned', 'diversity_mentioned', 'similarity_mentioned']\n",
    "total_articles = len(df2)\n",
    "\n",
    "for col in word_columns:\n",
    "    count = df2[col].sum()\n",
    "    percentage = (count / total_articles) * 100\n",
    "    print(f\"Number of articles containing '{col}': {count}\")\n",
    "    print(f\"Percentage of articles containing '{col}': {percentage:.2f}%\")\n",
    "\n",
    "combination_counts = df2.groupby(word_columns).size().reset_index(name='article_count')\n",
    "combination_counts = combination_counts.sort_values(by='article_count', ascending=False)\n",
    "\n",
    "print(\"Combination of word mentions (1=mentioned, 0=not mentioned):\")\n",
    "print(combination_counts.to_string(index=False))"
   ],
   "id": "8a0d4c665c37328f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "row = df2.iloc[180]\n",
    "print(row['title'])\n",
    "df2.head()\n",
    "\"\"\""
   ],
   "id": "63f3674148599df6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#checking which article uses none of the three words\n",
    "no_mentions_mask = df2[word_columns].sum(axis=1) == 0\n",
    "articles_with_no_mentions = df2[no_mentions_mask]\n",
    "print(articles_with_no_mentions[['title', 'pdf_filename']])\n",
    "\n"
   ],
   "id": "1954ef29948f3b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#checking the frequency of different keywords from article metadata\n",
    "from collections import Counter\n",
    "\n",
    "cleaned_keywords = (\n",
    "    df2['keywords']\n",
    "    .str.lower()  #lowercase\n",
    "    .str.replace(r\"[\\[\\]']\", \"\", regex=True)  #remove brackets and quotes\n",
    "    .str.split(',')\n",
    "    .explode()\n",
    "    .str.strip()  #remove leading/trailing whitespace\n",
    ")\n",
    "\n",
    "#counting frequencies\n",
    "keyword_counts = cleaned_keywords.value_counts()\n",
    "keyword_counts = keyword_counts[keyword_counts.index != '']\n",
    "print(\"Keyword frequencies:\")\n",
    "print(keyword_counts.head(20))"
   ],
   "id": "b81f623d39b941b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df2 = pd.read_csv('NeurIPS2024_Datasets_and_Benchmarks/metadata.csv')\n",
    "df2.info()"
   ],
   "id": "a1f388e535f26e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "row = df2.iloc[180]\n",
    "print(row['title'])\n",
    "df2.info()"
   ],
   "id": "1d66e110b62db6e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = df2.drop(df2.index[180])\n",
    "row = df.iloc[180]\n",
    "print(row['title'])"
   ],
   "id": "12d03c1b429416b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_bibliography(text: str) -> str:\n",
    "    #making sure text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    start_pattern = re.compile(r'(references|bibliography)', re.IGNORECASE | re.MULTILINE)\n",
    "    end_pattern = re.compile(r'(appendix|appendices|neurips paper checklist|neuripspaperchecklist)', re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "    start_match = start_pattern.search(text)\n",
    "\n",
    "    if not start_match:\n",
    "        return text\n",
    "\n",
    "    bib_start_index = start_match.start()\n",
    "    search_from_index = start_match.end()\n",
    "    end_match = end_pattern.search(text, pos=search_from_index)\n",
    "\n",
    "\n",
    "    if end_match:\n",
    "        bib_end_index = end_match.start()\n",
    "        #reconstruct text\n",
    "        text_before_bib = text[:bib_start_index]\n",
    "        text_after_bib_section = text[bib_end_index:]\n",
    "        return text_before_bib + text_after_bib_section\n",
    "    else:\n",
    "        return text[:bib_start_index]\n",
    "\n",
    "#creating new column with cleaned text\n",
    "df['fulltext_no_bib'] = df['fulltext'].apply(remove_bibliography)\n",
    "\n",
    "#checking if the function works\n",
    "sample_article = df.iloc[155]\n",
    "original_length = len(sample_article['fulltext'])\n",
    "cleaned_length = len(sample_article['fulltext_no_bib'])\n",
    "\n",
    "print(f\"Sample article title: {sample_article['title']}\")\n",
    "print(f\"Original fulltext length: {original_length} characters\")\n",
    "print(f\"Cleaned fulltext length:  {cleaned_length} characters\")\n",
    "print(f\"Characters removed:       {original_length - cleaned_length}\")"
   ],
   "id": "516181c7a1440504"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#comparing the fulltext and fulltext_no_bib columns\n",
    "import difflib\n",
    "\n",
    "try:\n",
    "    original_text = sample_article['fulltext']\n",
    "    cleaned_text = sample_article['fulltext_no_bib']\n",
    "\n",
    "    diff = difflib.unified_diff(original_text.splitlines(keepends=True), cleaned_text.splitlines(keepends=True), fromfile='original', tofile='no_bib', lineterm='')\n",
    "\n",
    "    print(\"Comparison:\")\n",
    "    diff_output = ''.join(diff)\n",
    "    print(diff_output)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error comparing fulltext and fulltext_no_bib: {e}\")"
   ],
   "id": "a67f8d01f051f841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#not perfect... but I think it works for now",
   "id": "5805f600a8c2a8f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#updating word mention columns based on 'fulltext_no_bib'\n",
    "search_terms = {\n",
    "    'representativity_mentioned': r'represent',\n",
    "    'diversity_mentioned': r'divers',\n",
    "    'similarity_mentioned': r'similar'\n",
    "}\n",
    "word_columns = list(search_terms.keys())\n",
    "\n",
    "print(\"\\nUpdating keyword columns based on 'fulltext_no_bib'...\")\n",
    "\n",
    "df['fulltext_no_bib'] = df['fulltext_no_bib'].astype(str).fillna('')\n",
    "\n",
    "for column_name, pattern in search_terms.items():\n",
    "    df[column_name] = df['fulltext_no_bib'].str.contains(\n",
    "        pattern,\n",
    "        case=False,\n",
    "        regex=True\n",
    "    ).astype(int)\n",
    "\n",
    "total_articles = len(df)\n",
    "\n",
    "\n",
    "\n",
    "for col in word_columns:\n",
    "    count = df[col].sum()\n",
    "    percentage = (count / total_articles) * 100\n",
    "    print(f\"Number of articles containing '{col}': {count}\")\n",
    "    print(f\"Percentage of articles containing '{col}': {percentage:.2f}%\")\n",
    "\n",
    "combination_counts = df.groupby(word_columns).size().reset_index(name='article_count')\n",
    "combination_counts = combination_counts.sort_values(by='article_count', ascending=False)\n",
    "\n",
    "print(\"Combination of word mentions (1=mentioned, 0=not mentioned):\")\n",
    "print(combination_counts.to_string(index=False))\n"
   ],
   "id": "652e6a500da2bd33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#removing duplicates in keywords column\n",
    "from collections import Counter\n",
    "\n",
    "normalization_map = {\n",
    "    'large language model': 'large language model',\n",
    "    'large language models': 'large language model',\n",
    "    'llm': 'large language model',\n",
    "    'llms': 'large language model',\n",
    "    'multimodal large language models': 'large language model',\n",
    "    'benchmark': 'benchmark',\n",
    "    'benchmarks': 'benchmark',\n",
    "    'benchmarking': 'benchmark',\n",
    "    'dataset': 'dataset',\n",
    "    'datasets': 'dataset',\n",
    "    'vision-language models': 'vision-language'\n",
    "}\n",
    "\n",
    "def normalize_keyword(keyword):\n",
    "    #normalizing keywords\n",
    "    return normalization_map.get(keyword, keyword)\n",
    "\n",
    "\n",
    "cleaned_keywords = (\n",
    "    df['keywords']\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[\\[\\]']\", \"\", regex=True)\n",
    "    .str.split(',')\n",
    "    .explode()\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "#applying normalization\n",
    "normalized_keywords = cleaned_keywords.apply(normalize_keyword)\n",
    "\n",
    "#count frequencies and remove empty strings\n",
    "keyword_counts_normalized = normalized_keywords.value_counts()\n",
    "keyword_counts_normalized = keyword_counts_normalized[keyword_counts_normalized.index != '']\n",
    "\n",
    "print(\"Updated keyword frequencies:\")\n",
    "print(keyword_counts_normalized.head(20))"
   ],
   "id": "e7f917f98b803752"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='viridis',\n",
    "    collocations=False\n",
    ").generate_from_frequencies(keyword_counts_normalized.to_dict())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Wordcloud on keywords.\")"
   ],
   "id": "69a1a98a5a62610d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#TODO\n",
    "#FINISH ARTICLE CODING/ANNOTATION\n",
    "#ADD COLUMN WITH PARAGRAPHS WHERE WORDS ARE MENTIONED\n",
    "#WRITE ARTICLE :))"
   ],
   "id": "d3e127756c08b5ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
